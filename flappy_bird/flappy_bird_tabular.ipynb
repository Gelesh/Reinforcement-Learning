{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flappy Bird"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1:\n",
    "Produce a Table of RL-based approaches (Policy Iteration, Value Iteration, Q Learning, TD, Monte Carlo) where each row is an approach and each column is a dimension that differentiates the approaches such as model free, which of the quintuple each uses (State, Action, Transitions, Rewards, etc..), and other dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2:\n",
    "Flappybird is a side-scrolling game where the agent must successfully navigate through gaps between pipes. The up arrow causes the bird to accelerate upwards. If the bird makes contact with the ground or pipes, or goes above the top of the screen, the game is over. For each pipe it passes through it gains a positive reward. Each time a terminal state is reached it receives a negative reward.\n",
    "\n",
    "Determine a good policy for Flappy Birds using  any one or more of the following algorithms (aim to get 140 points or more!):\n",
    "* Policy Iteration, Value Iteration, Q Learning, TD, Monte Carlo\n",
    "\n",
    "You may have to discretize the  space of  following parameters.\n",
    "* Vertical distance from lower pipe\n",
    "* Horizontal distance from next pair of pipes\n",
    "* Life: Dead or Living\n",
    "## Actions\n",
    "For each state, there two possible actions\n",
    "* Click\n",
    "* Do Nothing\n",
    "## Rewards\n",
    "The reward structure is purely based on the \"Life\" parameter. One possible such structure could be the following (feel free to explore more):\n",
    "* +1 if Flappy Bird is still alive\n",
    "* -1000 if Flappy Bird is dead\n",
    "\n",
    "## Flappy Birds Simulator:\n",
    "Please use the openai gym environment for this project:\n",
    "\n",
    "* https://gym.openai.com/envs/FlappyBird-v0/\n",
    "\n",
    "\n",
    "## Submission\n",
    "\n",
    "Part of your your report should be a video of how your agent learns showing progress after: after 10 minutes of  training; after 30 minutes; after 5 hours etc.; \n",
    "In addition please submit a notebook (with documented code) and a discussion section. \n",
    "\n",
    "# Deadline \n",
    "This Homework is due on Thursday July 5 at 9AM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declartions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import sys\n",
    "import os\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib.cbook import MatplotlibDeprecationWarning\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib as mpl\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "from pylab import rc\n",
    "import json\n",
    "import random\n",
    "#from itertools import izip\n",
    "import seaborn as sns\n",
    "sns.reset_orig()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent base class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    \"\"\"\n",
    "    The Agent class with utility methods   \n",
    "    \"\"\"\n",
    "    def __init__(self,                \n",
    "                 epsilon=.2, epsilon_decay=True, epsilon_decay_param=.01, \n",
    "                 tau=100, tau_decay=True, tau_decay_param=.01, \n",
    "                 policy_strategy='e-greedy'):\n",
    "        \n",
    "        \"\"\"Initialize agent parameters.\n",
    "        :param epsilon: Float value (0, 1) prob of taking random action vs. taking greedy action.\n",
    "        :param epsilon_decay: Bool indicating whether to use decay of epsilon over episodes.\n",
    "        :param epsilon_decay_param: Float param for decay given by epsilon*e^(-epsilon_decay_param * episode)\n",
    "        :param tau: Float value for temp. param in the softmax, tau -> 0 = greedy, tau -> infinity = random.\n",
    "        :param tau_decay: Bool indicating whether to use decay of tau over episodes.\n",
    "        :param tau_decay_param: Float param for decay given by tau*e^(-tau_decay_param * episode)\n",
    "        :param policy_strategy: String in {softmax, e-greedy, random}, exploration vs exploitation strategy.  \n",
    "        \"\"\"              \n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.epsilon_decay_param = epsilon_decay_param\n",
    "        self.tau = tau\n",
    "        self.tau_decay = tau_decay\n",
    "        self.tau_decay_param = tau_decay_param\n",
    "        self.policy_strategy = policy_strategy  \n",
    "        \n",
    "        self.moves = []\n",
    "            \n",
    "    #end def __init__  \n",
    "    \n",
    "    def choose_action(self, s):\n",
    "        \"\"\"Choose action for a TD algorithm that is updating using q values.\n",
    "\n",
    "        The policy strategy for choosing an action is either chosen using a\n",
    "        softmax strategy, epsilon greedy strategy, greedy strategy, or a random strategy.\n",
    "\n",
    "        :param s: Integer index of the current state index the agent is in.\n",
    "\n",
    "        :return a: Integer index of the chosen index for the action to take.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.policy_strategy == 'softmax':\n",
    "            a = self.softmax(s)\n",
    "        elif self.policy_strategy == 'e-greedy':\n",
    "            a = self.epsilon_greedy(s)\n",
    "        elif self.policy_strategy == 'greedy':\n",
    "            a = self.random_policy(self.qvalues[s])\n",
    "        else:\n",
    "            a = np.random.choice(self.actions)\n",
    "\n",
    "        return a\n",
    "    \n",
    "    def random_policy(self, list):\n",
    "        \n",
    "        \"\"\"Helper function to get the argmax of an array breaking ties randomly.\n",
    "        \n",
    "        :param arr: 1D or 1D numpy array to find the argmax for.\n",
    "    \n",
    "        :return choice or argmax_array: Choice is integer index of array with \n",
    "        the max value, argmax_array is array of integer index of max value in each \n",
    "        row of the original array.\n",
    "        \"\"\"\n",
    "    \n",
    "        arr = np.array(list)\n",
    "        \n",
    "        if len(arr.shape) == 1:\n",
    "            choice = np.random.choice(np.flatnonzero(arr == arr.max()))\n",
    "            return choice\n",
    "        else:\n",
    "            N = arr.shape[0]\n",
    "            argmax_array = np.zeros(N)\n",
    "    \n",
    "            for i in range(N):\n",
    "                choice = np.random.choice(np.flatnonzero(arr[i] == arr[i].max()))\n",
    "                argmax_array[i] = choice\n",
    "    \n",
    "        argmax_array = argmax_array.astype(int)\n",
    "    \n",
    "        return argmax_array\n",
    "    \n",
    "    #end def random_policy\n",
    "    \n",
    "    def epsilon_greedy(self, s):\n",
    "        \"\"\"Epsilon greedy exploration-exploitation strategy.\n",
    "\n",
    "        This policy strategy selects the current best action with probability\n",
    "        of 1 - epsilon, and a random action with probability epsilon.\n",
    "        \n",
    "        :param s: Integer index of the current state index the agent is in.\n",
    "\n",
    "        :return a: Integer index of the chosen index for the agent to take.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.epsilon_decay:\n",
    "            epsilon = self.epsilon * np.exp(-self.epsilon_decay_param * len(self.moves))\n",
    "        else:\n",
    "            epsilon = self.epsilon      \n",
    "            \n",
    "        if not np.random.binomial(1, epsilon):\n",
    "            a = self.random_policy(self.qvalues[s])\n",
    "        else:\n",
    "            a = np.random.choice(self.actions)\n",
    "\n",
    "        return a\n",
    "    #end def epsilon_greedy\n",
    "    \n",
    "    def softmax(self, s):\n",
    "        \"\"\"Softmax exploration-exploitation strategy.\n",
    "\n",
    "        This policy strategy uses a boltzman distribution with a temperature \n",
    "        parameter tau, to assign the probabilities of choosing an action based\n",
    "        off of the current q value of the state and action.\n",
    "\n",
    "        :param s: Integer index of the current state index the agent is in.\n",
    "\n",
    "        :return a: Integer index of the chosen index for the agent to take.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.tau_decay:\n",
    "            # Capping the minimum value of tau to prevent overflow issues.\n",
    "            tau = max(self.tau * np.exp(-self.tau_decay_param * self.episode), .1)\n",
    "        else:\n",
    "            tau = self.tau\n",
    "\n",
    "        if len(self.tau_choices) <= self.episode:\n",
    "            self.tau_choices.append(tau)\n",
    "\n",
    "        exp = lambda s, a: np.exp(self.qvalues[s, a]/tau)\n",
    "        values = []\n",
    "        probs = []\n",
    "\n",
    "        for a in self.actions:\n",
    "            # Catching overflow and returning random action if it occurs.\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings('error')\n",
    "                try:\n",
    "                    value = exp(s, a)\n",
    "                except RuntimeWarning:\n",
    "                    return self.random_policy(self.qvalues[s])\n",
    "\n",
    "            values.append(value) \n",
    "        \n",
    "        total = sum(values)\n",
    "        probs = [val/total for val in values]\n",
    "\n",
    "        try:\n",
    "            sample = np.random.multinomial(1, probs).tolist()\n",
    "            a = sample.index(1)\n",
    "        except:\n",
    "            # Return random action if there is a overflow issue.\n",
    "            a = self.random_policy(self.qvalues[s])\n",
    "\n",
    "        return a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flappy Bird Agent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FlappyBirdAgent(Agent):\n",
    "    \"\"\"\n",
    "    The Agent class that applies the Qlearning logic to Flappy bird game\n",
    "    After every iteration (iteration = 1 game that ends with the bird dying) updates Q values\n",
    "    After every SAVE_N iterations, saves the Q values to the local JSON file\n",
    "    \"\"\"\n",
    "    def __init__(self,                \n",
    "                 epsilon=.2, epsilon_decay=True, epsilon_decay_param=.01, \n",
    "                 tau=100, tau_decay=True, tau_decay_param=.01, \n",
    "                 policy_strategy='e-greedy'):\n",
    "        \n",
    "        \"\"\"Initialize agent parameters.\n",
    "        :param epsilon: Float value (0, 1) prob of taking random action vs. taking greedy action.\n",
    "        :param epsilon_decay: Bool indicating whether to use decay of epsilon over episodes.\n",
    "        :param epsilon_decay_param: Float param for decay given by epsilon*e^(-epsilon_decay_param * episode)\n",
    "        :param tau: Float value for temp. param in the softmax, tau -> 0 = greedy, tau -> infinity = random.\n",
    "        :param tau_decay: Bool indicating whether to use decay of tau over episodes.\n",
    "        :param tau_decay_param: Float param for decay given by tau*e^(-tau_decay_param * episode)\n",
    "        :param policy_strategy: String in {softmax, e-greedy, random}, exploration vs exploitation strategy.  \n",
    "        \"\"\"       \n",
    "        \n",
    "        super(FlappyBirdAgent, self).__init__(epsilon, epsilon_decay, epsilon_decay_param, \n",
    "                                                tau, tau_decay, tau_decay_param, \n",
    "                                                policy_strategy)\n",
    "        \n",
    "        self.gameCNT = 0 # Game count of current run, incremented after every death\n",
    "        self.SAVE_N = 25 # Number of iterations to dump Q values to JSON after  \n",
    "        \n",
    "        self.load_qvalues()\n",
    "        \n",
    "    #end def __init__\n",
    "\n",
    "    def load_qvalues(self):\n",
    "        \"\"\"\n",
    "        Load q values from a JSON file\n",
    "        \"\"\"\n",
    "        self.qvalues = {}\n",
    "        try:\n",
    "            fil = open('qvalues.json', 'r')\n",
    "        except IOError:\n",
    "            return\n",
    "        self.qvalues = json.load(fil)\n",
    "        fil.close()\n",
    "    #end def load_qvalues\n",
    "    \n",
    "    def map_state(self, xdif, ydif, vel):\n",
    "        \"\"\"\n",
    "        Map the (xdif, ydif, vel) to the respective state, with regards to the grids\n",
    "        The state is a string, \"xdif_ydif_vel\"\n",
    "\n",
    "        X -> [-40,-30...120] U [140, 210 ... 420]\n",
    "        Y -> [-300, -290 ... 160] U [180, 240 ... 420]\n",
    "        \"\"\"\n",
    "        if xdif < 140:\n",
    "            xdif = int(xdif) - (int(xdif) % 10)\n",
    "        else:\n",
    "            xdif = int(xdif) - (int(xdif) % 70)\n",
    "\n",
    "        if ydif < 180:\n",
    "            ydif = int(ydif) - (int(ydif) % 10)\n",
    "        else:\n",
    "            ydif = int(ydif) - (int(ydif) % 60)\n",
    "\n",
    "        return str(int(xdif))+'_'+str(int(ydif))+'_'+str(vel)\n",
    "    #end def map_state\n",
    "    \n",
    "    def act(self, xdif, ydif, vel):\n",
    "        \"\"\"\n",
    "        Chooses the best action with respect to the current state - Chooses 0 (don't flap) to tie-break\n",
    "        \"\"\"\n",
    "        state = self.map_state(xdif, ydif, vel)\n",
    "\n",
    "        self.moves.append( [self.last_state, self.last_action, state] ) # Add the experience to the history\n",
    "\n",
    "        self.last_state = state # Update the last_state with the current state\n",
    "                \n",
    "        self.last_action = self.choose_action(state)\n",
    "        \n",
    "        return self.last_action   \n",
    "       \n",
    "    #end def act\n",
    "    \n",
    "    def actOld(self, xdif, ydif, vel):\n",
    "        \"\"\"\n",
    "        Chooses the best action with respect to the current state - Chooses 0 (don't flap) to tie-break\n",
    "        \"\"\"\n",
    "        state = self.map_state(xdif, ydif, vel)\n",
    "\n",
    "        self.moves.append( [self.last_state, self.last_action, state] ) # Add the experience to the history\n",
    "\n",
    "        self.last_state = state # Update the last_state with the current state\n",
    "\n",
    "        if self.qvalues[state][0] >= self.qvalues[state][1]:\n",
    "            self.last_action = 0\n",
    "            return 0\n",
    "        else:\n",
    "            self.last_action = 1\n",
    "            return 1\n",
    "    \n",
    "    def get_last_state(self):\n",
    "        return self.last_state\n",
    "    #end def get_last_state\n",
    "   \n",
    "\n",
    "    def save_qvalues(self):\n",
    "        \"\"\"\n",
    "        Save the qvalues to the JSON file\n",
    "        \"\"\"\n",
    "        if self.gameCNT % self.SAVE_N == 0:\n",
    "            fil = open('qvalues.json', 'w')\n",
    "            json.dump(self.qvalues, fil)\n",
    "            fil.close()\n",
    "            print('Q-values updated on local file.')\n",
    "        #end if\n",
    "    #end def save_qvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flappy Bird Agent Q-Learning class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FlappyBirdAgentQLearning(FlappyBirdAgent):\n",
    "    \"\"\"\n",
    "    The Model Free Agent class that applies the Model Free algorithms to Flappy bird game\n",
    "    After every iteration (iteration = 1 game that ends with the bird dying) updates Q values\n",
    "    After every SAVE_N iterations, saves the Q values to the local JSON file\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 learning_rate = 0.7,\n",
    "                 discount_factor = 1.0,\n",
    "                 epsilon=.2, epsilon_decay=True, epsilon_decay_param=.01, \n",
    "                 tau=100, tau_decay=True, tau_decay_param=.01, \n",
    "                 policy_strategy='e-greedy'):\n",
    "        \n",
    "        \"\"\"Initialize agent parameters.\n",
    "        :param epsilon: Float value (0, 1) prob of taking random action vs. taking greedy action.\n",
    "        :param epsilon_decay: Bool indicating whether to use decay of epsilon over episodes.\n",
    "        :param epsilon_decay_param: Float param for decay given by epsilon*e^(-epsilon_decay_param * episode)\n",
    "        :param tau: Float value for temp. param in the softmax, tau -> 0 = greedy, tau -> infinity = random.\n",
    "        :param tau_decay: Bool indicating whether to use decay of tau over episodes.\n",
    "        :param tau_decay_param: Float param for decay given by tau*e^(-tau_decay_param * episode)\n",
    "        :param policy_strategy: String in {softmax, e-greedy, random}, exploration vs exploitation strategy.  \n",
    "        \"\"\"       \n",
    "        super(FlappyBirdAgentQLearning, self).__init__(epsilon, epsilon_decay, epsilon_decay_param, \n",
    "                                                tau, tau_decay, tau_decay_param, \n",
    "                                                policy_strategy)\n",
    "                \n",
    "        self.discount = discount_factor\n",
    "        self.r = {0: 1, 1: -1000} # Reward function\n",
    "        self.lr = learning_rate        \n",
    "        self.last_state = \"420_240_0\"\n",
    "        self.last_action = 0\n",
    "       \n",
    "        self.actions = [0,1] # 0=down 1=up\n",
    "                \n",
    "    #end def __init__\n",
    "    \n",
    "    def learn(self):\n",
    "        \"\"\"\n",
    "        Update qvalues via iterating over experiences\n",
    "        \"\"\"\n",
    "        history = list(reversed(self.moves))\n",
    "\n",
    "        # Flag if the bird died in the top pipe\n",
    "        high_death_flag = True if int(history[0][2].split('_')[1]) > 120 else False\n",
    "\n",
    "        # Q-learning score updates\n",
    "        t = 1\n",
    "        for exp in history:\n",
    "            state = exp[0]\n",
    "            act = exp[1]\n",
    "            res_state = exp[2]\n",
    "\n",
    "            # Select reward\n",
    "            if t == 1 or t == 2:\n",
    "                cur_reward = self.r[1]\n",
    "            elif high_death_flag and act:\n",
    "                cur_reward = self.r[1]\n",
    "                high_death_flag = False\n",
    "            else:\n",
    "                cur_reward = self.r[0]\n",
    "\n",
    "            # Update\n",
    "            self.qvalues[state][act] = (1-self.lr) * (self.qvalues[state][act]) + \\\n",
    "                                        self.lr * ( cur_reward + self.discount * max(self.qvalues[res_state]) )\n",
    "            t += 1\n",
    "        #end for\n",
    "\n",
    "        self.gameCNT += 1  # increase game count\n",
    "        self.save_qvalues()  # save q values (if game count % SAVE_N == 0)\n",
    "        self.moves = []  # clear history after updating strategies\n",
    "        \n",
    "        #lower exploration rate\n",
    "        self.epsilon = max(0, self.epsilon - self.epsilon_decay_param)\n",
    "    #end def learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flappy Bird Agent SARSA class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FlappyBirdAgentSARSA(FlappyBirdAgent):\n",
    "    \"\"\"\n",
    "    The Model Free Agent class that applies the Model Free algorithms to Flappy bird game\n",
    "    After every iteration (iteration = 1 game that ends with the bird dying) updates Q values\n",
    "    After every SAVE_N iterations, saves the Q values to the local JSON file\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 learning_rate = 0.7,\n",
    "                 discount_factor = 1.0,\n",
    "                 epsilon=.2, epsilon_decay=True, epsilon_decay_param=.01, \n",
    "                 tau=100, tau_decay=True, tau_decay_param=.01, \n",
    "                 policy_strategy='e-greedy'):\n",
    "        \n",
    "        \"\"\"Initialize agent parameters.\n",
    "        :param epsilon: Float value (0, 1) prob of taking random action vs. taking greedy action.\n",
    "        :param epsilon_decay: Bool indicating whether to use decay of epsilon over episodes.\n",
    "        :param epsilon_decay_param: Float param for decay given by epsilon*e^(-epsilon_decay_param * episode)\n",
    "        :param tau: Float value for temp. param in the softmax, tau -> 0 = greedy, tau -> infinity = random.\n",
    "        :param tau_decay: Bool indicating whether to use decay of tau over episodes.\n",
    "        :param tau_decay_param: Float param for decay given by tau*e^(-tau_decay_param * episode)\n",
    "        :param policy_strategy: String in {softmax, e-greedy, random}, exploration vs exploitation strategy.  \n",
    "        \"\"\"       \n",
    "        super(FlappyBirdAgentSARSA, self).__init__(epsilon, epsilon_decay, epsilon_decay_param, \n",
    "                                                tau, tau_decay, tau_decay_param, \n",
    "                                                policy_strategy)\n",
    "                \n",
    "        self.discount = discount_factor\n",
    "        self.r = {0: 1, 1: -1000} # Reward function\n",
    "        self.lr = learning_rate        \n",
    "        self.last_state = \"420_240_0\"\n",
    "        self.last_action = 0\n",
    "       \n",
    "        self.actions = [0,1] # 0=down 1=up\n",
    "                \n",
    "    #end def __init__\n",
    "    \n",
    "    def learn(self):\n",
    "        \"\"\"\n",
    "        Update qvalues via iterating over experiences\n",
    "        \"\"\"\n",
    "        history = list(reversed(self.moves))\n",
    "\n",
    "        # Flag if the bird died in the top pipe\n",
    "        high_death_flag = True if int(history[0][2].split('_')[1]) > 120 else False\n",
    "\n",
    "        # Q-learning score updates\n",
    "        t = 1\n",
    "        for exp in history:\n",
    "            state = exp[0]\n",
    "            act = exp[1]\n",
    "            res_state = exp[2]\n",
    "            \n",
    "            pos = 0\n",
    "\n",
    "            # Select reward\n",
    "            if t == 1 or t == 2:\n",
    "                pos = 1\n",
    "                cur_reward = self.r[pos]\n",
    "                \n",
    "            elif high_death_flag and act:\n",
    "                pos = 1\n",
    "                cur_reward = self.r[pos]\n",
    "                high_death_flag = False\n",
    "            else:\n",
    "                pos = 0\n",
    "                cur_reward = self.r[pos]\n",
    "\n",
    "            # Update\n",
    "            self.qvalues[state][act] = (1-self.lr) * (self.qvalues[state][act]) + \\\n",
    "                                        self.lr * ( cur_reward + self.discount * self.qvalues[res_state][pos])\n",
    "            t += 1\n",
    "        #end for\n",
    "\n",
    "        self.gameCNT += 1  # increase game count\n",
    "        self.save_qvalues()  # save q values (if game count % SAVE_N == 0)\n",
    "        self.moves = []  # clear history after updating strategies\n",
    "        \n",
    "        #lower exploration rate\n",
    "        self.epsilon = max(0, self.epsilon - self.epsilon_decay_param)\n",
    "    #end def learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flappy Bird Environment Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import pygame\n",
    "from pygame.locals import *\n",
    "\n",
    "class FlappyBirdEnviornment(object):    \n",
    "    \n",
    "    def __init__(self, agent, play_sounds = False):  \n",
    "        self.agent = agent\n",
    "        \n",
    "        self.FPS = 60\n",
    "        self.SCREENWIDTH  = 288\n",
    "        self.SCREENHEIGHT = 512\n",
    "        self.play_sounds = play_sounds\n",
    "\n",
    "        # amount by which base can maximum shift to left\n",
    "        self.PIPEGAPSIZE  = 100 # gap between upper and lower part of pipe\n",
    "        self.BASEY        = self.SCREENHEIGHT * 0.79\n",
    "        # image, sound and hitmask  dicts\n",
    "        self.IMAGES, self.SOUNDS, self.HITMASKS = {}, {}, {}\n",
    "\n",
    "        # list of all possible players (tuple of 3 positions of flap)\n",
    "        self.PLAYERS_LIST = (\n",
    "            # red bird\n",
    "            (\n",
    "                'assets/sprites/redbird-upflap.png',\n",
    "                'assets/sprites/redbird-midflap.png',\n",
    "                'assets/sprites/redbird-downflap.png',\n",
    "            ),\n",
    "            # blue bird\n",
    "            (\n",
    "                # amount by which base can maximum shift to left\n",
    "                'assets/sprites/bluebird-upflap.png',\n",
    "                'assets/sprites/bluebird-midflap.png',\n",
    "                'assets/sprites/bluebird-downflap.png',\n",
    "            ),\n",
    "            # yellow bird\n",
    "            (\n",
    "                'assets/sprites/yellowbird-upflap.png',\n",
    "                'assets/sprites/yellowbird-midflap.png',\n",
    "                'assets/sprites/yellowbird-downflap.png',\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # list of backgrounds\n",
    "        self.BACKGROUNDS_LIST = (\n",
    "            'assets/sprites/background-day.png',\n",
    "            'assets/sprites/background-night.png',\n",
    "        )\n",
    "\n",
    "        # list of pipes\n",
    "        self.PIPES_LIST = (\n",
    "            'assets/sprites/pipe-green.png',\n",
    "            'assets/sprites/pipe-red.png',\n",
    "        )\n",
    "\n",
    "        self.episode = 0\n",
    "        self.history = pd.DataFrame(columns=[\"Episode\", \"Score\"])\n",
    "        self.start = datetime.datetime.now()\n",
    "        \n",
    "    #end def __int__\n",
    "\n",
    "    def simulate(self, max_score):\n",
    "        \n",
    "        pygame.init()\n",
    "        self.FPSCLOCK = pygame.time.Clock()\n",
    "        self.SCREEN = pygame.display.set_mode((self.SCREENWIDTH, self.SCREENHEIGHT))\n",
    "        pygame.display.set_caption('Flappy Bird')\n",
    "\n",
    "        # numbers sprites for score display\n",
    "        self.IMAGES['numbers'] = (\n",
    "            pygame.image.load('assets/sprites/0.png').convert_alpha(),\n",
    "            pygame.image.load('assets/sprites/1.png').convert_alpha(),\n",
    "            pygame.image.load('assets/sprites/2.png').convert_alpha(),\n",
    "            pygame.image.load('assets/sprites/3.png').convert_alpha(),\n",
    "            pygame.image.load('assets/sprites/4.png').convert_alpha(),\n",
    "            pygame.image.load('assets/sprites/5.png').convert_alpha(),\n",
    "            pygame.image.load('assets/sprites/6.png').convert_alpha(),\n",
    "            pygame.image.load('assets/sprites/7.png').convert_alpha(),\n",
    "            pygame.image.load('assets/sprites/8.png').convert_alpha(),\n",
    "            pygame.image.load('assets/sprites/9.png').convert_alpha()\n",
    "        )\n",
    "\n",
    "        # game over sprite\n",
    "        self.IMAGES['gameover'] = pygame.image.load('assets/sprites/gameover.png').convert_alpha()\n",
    "        # message sprite for welcome screen\n",
    "        self.IMAGES['message'] = pygame.image.load('assets/sprites/message.png').convert_alpha()\n",
    "        # base (ground) sprite\n",
    "        self.IMAGES['base'] = pygame.image.load('assets/sprites/base.png').convert_alpha()\n",
    "\n",
    "        # sounds\n",
    "        if 'win' in sys.platform:\n",
    "            soundExt = '.wav'\n",
    "        else:\n",
    "            soundExt = '.ogg'\n",
    "\n",
    "        self.SOUNDS['die']    = pygame.mixer.Sound('assets/audio/die' + soundExt)\n",
    "        self.SOUNDS['hit']    = pygame.mixer.Sound('assets/audio/hit' + soundExt)\n",
    "        self.SOUNDS['point']  = pygame.mixer.Sound('assets/audio/point' + soundExt)\n",
    "        self.SOUNDS['swoosh'] = pygame.mixer.Sound('assets/audio/swoosh' + soundExt)\n",
    "        self.SOUNDS['wing']   = pygame.mixer.Sound('assets/audio/wing' + soundExt)\n",
    "\n",
    "        while True:\n",
    "            # select random background sprites\n",
    "            randBg = random.randint(0, len(self.BACKGROUNDS_LIST) - 1)\n",
    "            self.IMAGES['background'] = pygame.image.load(self.BACKGROUNDS_LIST[randBg]).convert()\n",
    "\n",
    "            # select random player sprites\n",
    "            randPlayer = random.randint(0, len(self.PLAYERS_LIST) - 1)\n",
    "            self.IMAGES['player'] = (\n",
    "                pygame.image.load(self.PLAYERS_LIST[randPlayer][0]).convert_alpha(),\n",
    "                pygame.image.load(self.PLAYERS_LIST[randPlayer][1]).convert_alpha(),\n",
    "                pygame.image.load(self.PLAYERS_LIST[randPlayer][2]).convert_alpha(),\n",
    "            )\n",
    "\n",
    "            # select random pipe sprites\n",
    "            pipeindex = random.randint(0, len(self.PIPES_LIST) - 1)\n",
    "            self.IMAGES['pipe'] = (\n",
    "                pygame.transform.rotate(\n",
    "                    pygame.image.load(self.PIPES_LIST[pipeindex]).convert_alpha(), 180),\n",
    "                pygame.image.load(self.PIPES_LIST[pipeindex]).convert_alpha(),\n",
    "            )\n",
    "\n",
    "            # hismask for pipes\n",
    "            self.HITMASKS['pipe'] = (\n",
    "                self.getHitmask(self.IMAGES['pipe'][0]),\n",
    "                self.getHitmask(self.IMAGES['pipe'][1]),\n",
    "            )\n",
    "\n",
    "            # hitmask for player\n",
    "            self.HITMASKS['player'] = (\n",
    "                self.getHitmask(self.IMAGES['player'][0]),\n",
    "                self.getHitmask(self.IMAGES['player'][1]),\n",
    "                self.getHitmask(self.IMAGES['player'][2]),\n",
    "            )\n",
    "\n",
    "            movementInfo = self.showWelcomeAnimation()\n",
    "            crashInfo =  self.play(movementInfo, max_score)\n",
    "            self.showGameOverScreen(crashInfo)\n",
    "\n",
    "\n",
    "    def showWelcomeAnimation(self):\n",
    "        \"\"\"Shows welcome screen animation of flappy bird\"\"\"\n",
    "        # index of player to blit on screen\n",
    "        playerIndex = 0\n",
    "        playerIndexGen = cycle([0, 1, 2, 1])\n",
    "        # iterator used to change playerIndex after every 5th iteration\n",
    "        loopIter = 0\n",
    "\n",
    "        playerx = int(self.SCREENWIDTH * 0.2)\n",
    "        playery = int((self.SCREENHEIGHT - self.IMAGES['player'][0].get_height()) / 2)\n",
    "\n",
    "        messagex = int((self.SCREENWIDTH - self.IMAGES['message'].get_width()) / 2)\n",
    "        messagey = int(self.SCREENHEIGHT * 0.12)\n",
    "\n",
    "        basex = 0\n",
    "        # amount by which base can maximum shift to left\n",
    "        baseShift = self.IMAGES['base'].get_width() - self.IMAGES['background'].get_width()\n",
    "\n",
    "        # player shm for up-down motion on welcome screen\n",
    "        playerShmVals = {'val': 0, 'dir': 1}\n",
    "\n",
    "\n",
    "        while True:\n",
    "            ''' De-activated the press key functionality\n",
    "\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == QUIT or (event.type == KEYDOWN and event.key == K_ESCAPE):\n",
    "                    pygame.quit()\n",
    "                    sys.exit()\n",
    "                if event.type == KEYDOWN and (event.key == K_SPACE or event.key == K_UP):\n",
    "                    # make first flap sound and return values for mainGame\n",
    "                    SOUNDS['wing'].play()\n",
    "                    return {\n",
    "                        'playery': playery + playerShmVals['val'],\n",
    "                        'basex': basex,\n",
    "                        'playerIndexGen': playerIndexGen,\n",
    "                    }\n",
    "            '''\n",
    "            if self.play_sounds == True: self.SOUNDS['wing'].play()\n",
    "\n",
    "            return {\n",
    "                'playery': playery + playerShmVals['val'],\n",
    "                'basex': basex,\n",
    "                'playerIndexGen': playerIndexGen,\n",
    "            }\n",
    "\n",
    "            # adjust playery, playerIndex, basex\n",
    "            if (loopIter + 1) % 5 == 0:\n",
    "                playerIndex = next(playerIndexGen)\n",
    "\n",
    "            loopIter = (loopIter + 1) % 30\n",
    "            basex = -((-basex + 4) % baseShift)\n",
    "            playerShm(playerShmVals)\n",
    "\n",
    "            # draw sprites\n",
    "            self.SCREEN.blit(self.IMAGES['background'], (0,0))\n",
    "            self.SCREEN.blit(self.IMAGES['player'][playerIndex],\n",
    "                        (playerx, playery + playerShmVals['val']))\n",
    "            self.SCREEN.blit(self.IMAGES['message'], (messagex, messagey))\n",
    "            self.SCREEN.blit(self.IMAGES['base'], (basex, self.BASEY))\n",
    "\n",
    "            pygame.display.update()\n",
    "            self.FPSCLOCK.tick(FPS)\n",
    "\n",
    "\n",
    "    def play(self,movementInfo, max_iterations):\n",
    "\n",
    "        score = playerIndex = loopIter = 0\n",
    "        playerIndexGen = movementInfo['playerIndexGen']\n",
    "\n",
    "        playerx, playery = int(self.SCREENWIDTH * 0.2), movementInfo['playery']\n",
    "\n",
    "        basex = movementInfo['basex']\n",
    "        baseShift = self.IMAGES['base'].get_width() - self.IMAGES['background'].get_width()\n",
    "\n",
    "        # get 2 new pipes to add to upperPipes lowerPipes list\n",
    "        newPipe1 = self.getRandomPipe()\n",
    "        newPipe2 = self.getRandomPipe()\n",
    "\n",
    "        # list of upper pipes\n",
    "        upperPipes = [\n",
    "            {'x': self.SCREENWIDTH + 200, 'y': newPipe1[0]['y']},\n",
    "            {'x': self.SCREENWIDTH + 200 + (self.SCREENWIDTH / 2), 'y': newPipe2[0]['y']},\n",
    "        ]\n",
    "\n",
    "        # list of lowerpipe\n",
    "        lowerPipes = [\n",
    "            {'x': self.SCREENWIDTH + 200, 'y': newPipe1[1]['y']},\n",
    "            {'x': self.SCREENWIDTH + 200 + (self.SCREENWIDTH / 2), 'y': newPipe2[1]['y']},\n",
    "        ]\n",
    "\n",
    "        pipeVelX = -4\n",
    "\n",
    "        # player velocity, max velocity, downward accleration, accleration on flap\n",
    "        playerVelY    =  -9   # player's velocity along Y, default same as playerFlapped\n",
    "        playerMaxVelY =  10   # max vel along Y, max descend speed\n",
    "        playerMinVelY =  -8   # min vel along Y, max ascend speed\n",
    "        playerAccY    =   1   # players downward accleration\n",
    "        playerFlapAcc =  -9   # players speed on flapping\n",
    "        playerFlapped = False # True when player flaps\n",
    "\n",
    "        while True:\n",
    "                       \n",
    "            if max_iterations < self.episode:\n",
    "                end = datetime.datetime.now()\n",
    "    \n",
    "                print('duration: {} to run episodes: {}'.format(end- self.start, max_iterations))\n",
    "    \n",
    "                plt.scatter(self.history.Episode, self.history.Score)\n",
    "                plt.show()\n",
    "                    \n",
    "                pygame.quit()\n",
    "                sys.exit()\n",
    "                \n",
    "            if -playerx + lowerPipes[0]['x'] > -30:\n",
    "                myPipe = lowerPipes[0]\n",
    "            else:\n",
    "                myPipe = lowerPipes[1]\n",
    "\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == QUIT or (event.type == KEYDOWN and event.key == K_ESCAPE):\n",
    "                    pygame.quit()\n",
    "                    sys.exit()\n",
    "                    \n",
    "                if (event.type == KEYDOWN and (event.key == K_SPACE or event.key == K_UP)):\n",
    "                    if playery > -2 * self.IMAGES['player'][0].get_height():\n",
    "                        playerVelY = playerFlapAcc\n",
    "                        playerFlapped = True\n",
    "                        if self.play_sounds == True: self.SOUNDS['wing'].play()\n",
    "\n",
    "            if self.agent.act(-playerx + myPipe['x'], - playery + myPipe['y'], playerVelY):\n",
    "                if playery > -2 * self.IMAGES['player'][0].get_height():\n",
    "                    playerVelY = playerFlapAcc\n",
    "                    playerFlapped = True\n",
    "                    if self.play_sounds == True: self.SOUNDS['wing'].play()\n",
    "\n",
    "            # check for crash here\n",
    "            crashTest = self.checkCrash({'x': playerx, 'y': playery, 'index': playerIndex},\n",
    "                                   upperPipes, lowerPipes)\n",
    "            if crashTest[0]:\n",
    "                \n",
    "                self.episode += 1\n",
    "                \n",
    "                # Update the q scores\n",
    "                self.agent.learn()\n",
    "                \n",
    "                self.history.loc[len(self.history)] = [self.episode, score]\n",
    "                print(\"episode: {} score: {}\".format(self.episode, score))\n",
    "                \n",
    "                return {\n",
    "                    'y': playery,\n",
    "                    'groundCrash': crashTest[1],\n",
    "                    'basex': basex,\n",
    "                    'upperPipes': upperPipes,\n",
    "                    'lowerPipes': lowerPipes,\n",
    "                    'score': score,\n",
    "                    'playerVelY': playerVelY,\n",
    "                }\n",
    "\n",
    "            # check for score\n",
    "            playerMidPos = playerx + self.IMAGES['player'][0].get_width() / 2\n",
    "            for pipe in upperPipes:\n",
    "                pipeMidPos = pipe['x'] + self.IMAGES['pipe'][0].get_width() / 2\n",
    "                if pipeMidPos <= playerMidPos < pipeMidPos + 4:\n",
    "                    score += 1\n",
    "                    if self.play_sounds == True: self.SOUNDS['point'].play()\n",
    "\n",
    "            # playerIndex basex change\n",
    "            if (loopIter + 1) % 3 == 0:\n",
    "                playerIndex = next(playerIndexGen)\n",
    "            loopIter = (loopIter + 1) % 30\n",
    "            basex = -((-basex + 100) % baseShift)\n",
    "\n",
    "            # player's movement\n",
    "            if playerVelY < playerMaxVelY and not playerFlapped:\n",
    "                playerVelY += playerAccY\n",
    "            if playerFlapped:\n",
    "                playerFlapped = False\n",
    "            playerHeight = self.IMAGES['player'][playerIndex].get_height()\n",
    "            playery += min(playerVelY, self.BASEY - playery - playerHeight)\n",
    "\n",
    "\n",
    "            # move pipes to left\n",
    "            for uPipe, lPipe in zip(upperPipes, lowerPipes):\n",
    "                uPipe['x'] += pipeVelX\n",
    "                lPipe['x'] += pipeVelX\n",
    "\n",
    "\n",
    "            # add new pipe when first pipe is about to touch left of screen\n",
    "            if 0 < upperPipes[0]['x'] < 5:\n",
    "                newPipe = self.getRandomPipe()\n",
    "                upperPipes.append(newPipe[0])\n",
    "                lowerPipes.append(newPipe[1])\n",
    "\n",
    "            # remove first pipe if its out of the screen\n",
    "            if upperPipes[0]['x'] < - self.IMAGES['pipe'][0].get_width():\n",
    "                upperPipes.pop(0)\n",
    "                lowerPipes.pop(0)\n",
    "\n",
    "            # draw sprites\n",
    "            self.SCREEN.blit(self.IMAGES['background'], (0,0))\n",
    "\n",
    "            for uPipe, lPipe in zip(upperPipes, lowerPipes):\n",
    "                self.SCREEN.blit(self.IMAGES['pipe'][0], (uPipe['x'], uPipe['y']))\n",
    "                self.SCREEN.blit(self.IMAGES['pipe'][1], (lPipe['x'], lPipe['y']))\n",
    "\n",
    "\n",
    "\n",
    "            self.SCREEN.blit(self.IMAGES['base'], (basex, self.BASEY))\n",
    "            # print score so player overlaps the score\n",
    "            self.showScore(score)\n",
    "            self.SCREEN.blit(self.IMAGES['player'][playerIndex], (playerx, playery))\n",
    "\n",
    "            pygame.display.update()\n",
    "            self.FPSCLOCK.tick(self.FPS)\n",
    "\n",
    "\n",
    "    def showGameOverScreen(self,crashInfo):\n",
    "        \"\"\"crashes the player down and shows gameover image\"\"\"\n",
    "        score = crashInfo['score']\n",
    "        playerx = self.SCREENWIDTH * 0.2\n",
    "        playery = crashInfo['y']\n",
    "        playerHeight = self.IMAGES['player'][0].get_height()\n",
    "        playerVelY = crashInfo['playerVelY']\n",
    "        playerAccY = 2\n",
    "\n",
    "        basex = crashInfo['basex']\n",
    "\n",
    "        upperPipes, lowerPipes = crashInfo['upperPipes'], crashInfo['lowerPipes']\n",
    "\n",
    "        # play hit and die sounds\n",
    "        if self.play_sounds == True: self.SOUNDS['hit'].play()\n",
    "        if not crashInfo['groundCrash']:\n",
    "            if self.play_sounds == True: self.SOUNDS['die'].play()\n",
    "\n",
    "        while True:\n",
    "            ''' De-activated press key functionality\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == QUIT or (event.type == KEYDOWN and event.key == K_ESCAPE):\n",
    "                    pygame.quit()\n",
    "                    sys.exit()\n",
    "                if event.type == KEYDOWN and (event.key == K_SPACE or event.key == K_UP):\n",
    "                    if playery + playerHeight >= BASEY - 1:\n",
    "                        return\n",
    "            '''\n",
    "            return ### Must remove to activate press-key functionality\n",
    "\n",
    "            # player y shift\n",
    "            if playery + playerHeight < self.BASEY - 1:\n",
    "                playery += min(playerVelY, self.BASEY - playery - playerHeight)\n",
    "\n",
    "            # player velocity change\n",
    "            if playerVelY < 15:\n",
    "                playerVelY += playerAccY\n",
    "\n",
    "            # draw sprites\n",
    "            self.SCREEN.blit(self.IMAGES['background'], (0,0))\n",
    "\n",
    "            for uPipe, lPipe in zip(upperPipes, lowerPipes):\n",
    "                SCREEN.blit(self.IMAGES['pipe'][0], (uPipe['x'], uPipe['y']))\n",
    "                SCREEN.blit(self.IMAGES['pipe'][1], (lPipe['x'], lPipe['y']))\n",
    "\n",
    "            self.SCREEN.blit(self.IMAGES['base'], (basex, BASEY))\n",
    "            self.showScore(score)\n",
    "            self.SCREEN.blit(self.IMAGES['player'][1], (playerx,playery))\n",
    "\n",
    "            self.FPSCLOCK.tick(FPS)\n",
    "            pygame.display.update()\n",
    "\n",
    "\n",
    "    def playerShm(playerShm):\n",
    "        \"\"\"oscillates the value of playerShm['val'] between 8 and -8\"\"\"\n",
    "        if abs(playerShm['val']) == 8:\n",
    "            playerShm['dir'] *= -1\n",
    "\n",
    "        if playerShm['dir'] == 1:\n",
    "             playerShm['val'] += 1\n",
    "        else:\n",
    "            playerShm['val'] -= 1\n",
    "\n",
    "\n",
    "    def getRandomPipe(self):\n",
    "        \"\"\"returns a randomly generated pipe\"\"\"\n",
    "        # y of gap between upper and lower pipe\n",
    "        gapY = random.randrange(0, int(self.BASEY * 0.6 - self.PIPEGAPSIZE))\n",
    "        gapY += int(self.BASEY * 0.2)\n",
    "        pipeHeight = self.IMAGES['pipe'][0].get_height()\n",
    "        pipeX = self.SCREENWIDTH + 10\n",
    "\n",
    "        return [\n",
    "            {'x': pipeX, 'y': gapY - pipeHeight},  # upper pipe\n",
    "            {'x': pipeX, 'y': gapY + self.PIPEGAPSIZE}, # lower pipe\n",
    "        ]\n",
    "\n",
    "\n",
    "    def showScore(self, score):\n",
    "        \"\"\"displays score in center of screen\"\"\"\n",
    "        scoreDigits = [int(x) for x in list(str(score))]\n",
    "        totalWidth = 0 # total width of all numbers to be printed\n",
    "\n",
    "        for digit in scoreDigits:\n",
    "            totalWidth += self.IMAGES['numbers'][digit].get_width()\n",
    "\n",
    "        Xoffset = (self.SCREENWIDTH - totalWidth) / 2\n",
    "\n",
    "        for digit in scoreDigits:\n",
    "            self.SCREEN.blit(self.IMAGES['numbers'][digit], (Xoffset, self.SCREENHEIGHT * 0.1))\n",
    "            Xoffset += self.IMAGES['numbers'][digit].get_width()\n",
    "\n",
    "\n",
    "    def checkCrash(self, player, upperPipes, lowerPipes):\n",
    "        \"\"\"returns True if player collders with base or pipes.\"\"\"\n",
    "        pi = player['index']\n",
    "        player['w'] = self.IMAGES['player'][0].get_width()\n",
    "        player['h'] = self.IMAGES['player'][0].get_height()\n",
    "\n",
    "        # if player crashes into ground\n",
    "        if (player['y'] + player['h'] >= self.BASEY - 1 ) or (player['y'] + player['h'] <= 0):\n",
    "            return [True, True]\n",
    "        else:\n",
    "\n",
    "            playerRect = pygame.Rect(player['x'], player['y'],\n",
    "                          player['w'], player['h'])\n",
    "            pipeW = self.IMAGES['pipe'][0].get_width()\n",
    "            pipeH = self.IMAGES['pipe'][0].get_height()\n",
    "\n",
    "            for uPipe, lPipe in zip(upperPipes, lowerPipes):\n",
    "                # upper and lower pipe rects\n",
    "                uPipeRect = pygame.Rect(uPipe['x'], uPipe['y'], pipeW, pipeH)\n",
    "                lPipeRect = pygame.Rect(lPipe['x'], lPipe['y'], pipeW, pipeH)\n",
    "\n",
    "                # player and upper/lower pipe hitmasks\n",
    "                pHitMask = self.HITMASKS['player'][pi]\n",
    "                uHitmask = self.HITMASKS['pipe'][0]\n",
    "                lHitmask = self.HITMASKS['pipe'][1]\n",
    "\n",
    "                # if bird collided with upipe or lpipe\n",
    "                uCollide = self.pixelCollision(playerRect, uPipeRect, pHitMask, uHitmask)\n",
    "                lCollide = self.pixelCollision(playerRect, lPipeRect, pHitMask, lHitmask)\n",
    "\n",
    "                if uCollide or lCollide:\n",
    "                    return [True, False]\n",
    "\n",
    "        return [False, False]\n",
    "\n",
    "    def pixelCollision(self, rect1, rect2, hitmask1, hitmask2):\n",
    "        \"\"\"Checks if two objects collide and not just their rects\"\"\"\n",
    "        rect = rect1.clip(rect2)\n",
    "\n",
    "        if rect.width == 0 or rect.height == 0:\n",
    "            return False\n",
    "\n",
    "        x1, y1 = rect.x - rect1.x, rect.y - rect1.y\n",
    "        x2, y2 = rect.x - rect2.x, rect.y - rect2.y\n",
    "\n",
    "        for x in range(rect.width):\n",
    "            for y in range(rect.height):\n",
    "                if hitmask1[x1+x][y1+y] and hitmask2[x2+x][y2+y]:\n",
    "                    return True\n",
    "        return False\n",
    "\n",
    "    def getHitmask(self, image):\n",
    "        \"\"\"returns a hitmask using an image's alpha.\"\"\"\n",
    "        mask = []\n",
    "        for x in range(image.get_width()):\n",
    "            mask.append([])\n",
    "            for y in range(image.get_height()):\n",
    "                mask[x].append(bool(image.get_at((x,y))[3]))\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Flappy Bird Tabular TD Algorithms - Q-Learning and SARSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "max_episodes = 100\n",
    "fbAgentSARSA = FlappyBirdAgentSARSA()\n",
    "fbEnv = FlappyBirdEnviornment(fbAgentSARSA)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fbEnv.simulate(max_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1 score: 0\n",
      "episode: 2 score: 0\n",
      "episode: 3 score: 0\n",
      "episode: 4 score: 0\n",
      "episode: 5 score: 0\n",
      "episode: 6 score: 0\n",
      "episode: 7 score: 0\n",
      "episode: 8 score: 0\n",
      "episode: 9 score: 0\n",
      "episode: 10 score: 0\n",
      "episode: 11 score: 0\n",
      "episode: 12 score: 0\n",
      "episode: 13 score: 0\n",
      "episode: 14 score: 3\n",
      "episode: 15 score: 0\n",
      "episode: 16 score: 373\n",
      "episode: 17 score: 236\n",
      "episode: 18 score: 0\n",
      "episode: 19 score: 492\n",
      "episode: 20 score: 0\n",
      "episode: 21 score: 145\n",
      "episode: 22 score: 350\n",
      "episode: 23 score: 33\n",
      "episode: 24 score: 37\n",
      "Q-values updated on local file.\n",
      "episode: 25 score: 59\n",
      "episode: 26 score: 173\n",
      "episode: 27 score: 295\n",
      "episode: 28 score: 480\n",
      "episode: 29 score: 481\n",
      "episode: 30 score: 223\n",
      "episode: 31 score: 17\n",
      "episode: 32 score: 14\n",
      "episode: 33 score: 247\n",
      "episode: 34 score: 138\n",
      "episode: 35 score: 21\n",
      "episode: 36 score: 39\n",
      "episode: 37 score: 81\n",
      "episode: 38 score: 49\n",
      "episode: 39 score: 82\n",
      "episode: 40 score: 65\n",
      "episode: 41 score: 57\n",
      "episode: 42 score: 17\n",
      "episode: 43 score: 84\n",
      "episode: 44 score: 407\n",
      "episode: 45 score: 191\n",
      "episode: 46 score: 58\n",
      "episode: 47 score: 223\n",
      "episode: 48 score: 19\n",
      "episode: 49 score: 56\n",
      "Q-values updated on local file.\n",
      "episode: 50 score: 170\n",
      "episode: 51 score: 142\n",
      "episode: 52 score: 25\n",
      "episode: 53 score: 49\n",
      "episode: 54 score: 103\n",
      "episode: 55 score: 136\n",
      "episode: 56 score: 161\n",
      "episode: 57 score: 62\n",
      "episode: 58 score: 181\n",
      "episode: 59 score: 9\n",
      "episode: 60 score: 67\n",
      "episode: 61 score: 63\n",
      "episode: 62 score: 192\n",
      "episode: 63 score: 596\n",
      "episode: 64 score: 1047\n",
      "episode: 65 score: 90\n",
      "episode: 66 score: 147\n",
      "episode: 67 score: 825\n",
      "episode: 68 score: 312\n",
      "episode: 69 score: 67\n",
      "episode: 70 score: 75\n",
      "episode: 71 score: 71\n",
      "episode: 72 score: 161\n",
      "episode: 73 score: 515\n",
      "episode: 74 score: 47\n",
      "Q-values updated on local file.\n",
      "episode: 75 score: 160\n",
      "episode: 76 score: 20\n",
      "episode: 77 score: 203\n",
      "episode: 78 score: 63\n",
      "episode: 79 score: 65\n",
      "episode: 80 score: 36\n",
      "episode: 81 score: 281\n",
      "episode: 82 score: 321\n",
      "episode: 83 score: 251\n",
      "episode: 84 score: 165\n",
      "episode: 85 score: 16\n",
      "episode: 86 score: 64\n",
      "episode: 87 score: 107\n",
      "episode: 88 score: 363\n",
      "episode: 89 score: 71\n",
      "episode: 90 score: 157\n",
      "episode: 91 score: 111\n",
      "episode: 92 score: 177\n",
      "episode: 93 score: 355\n",
      "episode: 94 score: 51\n",
      "episode: 95 score: 119\n",
      "episode: 96 score: 137\n",
      "episode: 97 score: 28\n",
      "episode: 98 score: 386\n",
      "episode: 99 score: 279\n",
      "Q-values updated on local file.\n",
      "episode: 100 score: 229\n",
      "episode: 101 score: 780\n",
      "duration: 2:45:52.346612 to run episodes: 100\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1570ec0a7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "max_episodes = 100\n",
    "fbAgentQLearning = FlappyBirdAgentQLearning()\n",
    "fbEnvQ = FlappyBirdEnviornment(fbAgentQLearning)\n",
    "\n",
    "if __name__ == '__main__':        \n",
    "    fbEnvQ.simulate(max_episodes) \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
